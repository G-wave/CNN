{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obama_image = face_recognition.load_image_file(\"Obama.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biden_image = face_recognition.load_image_file(\"Biden.jpeg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_face_names = [\n",
    "    \"Barack Obama\",\n",
    "    \"Joe Biden\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (128,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-336a7d673a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mface_encoding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# See if the face is a match for the known face(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_face_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Unknown\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/face_recognition/api.py\u001b[0m in \u001b[0;36mcompare_faces\u001b[0;34m(known_face_encodings, face_encoding_to_check, tolerance)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mknown_face_encodings\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mface\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_face_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encoding_to_check\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/face_recognition/api.py\u001b[0m in \u001b[0;36mface_distance\u001b[0;34m(face_encodings, face_to_compare)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_encodings\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mface_to_compare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (128,) "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenC V uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # If a match was found in known_face_encodings, just use the first one.\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_face_names[first_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "\n",
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "    pil_image = Image.fromarray(image)\n",
    "    d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "\n",
    "    # Make the eyebrows into a nightmare\n",
    "    d.polygon(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    d.polygon(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 128))\n",
    "    d.line(face_landmarks['left_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "    d.line(face_landmarks['right_eyebrow'], fill=(68, 54, 39, 150), width=5)\n",
    "\n",
    "    # Gloss the lips\n",
    "    d.polygon(face_landmarks['top_lip'], fill=(150, 0, 0, 128))\n",
    "    d.polygon(face_landmarks['bottom_lip'], fill=(150, 0, 0, 128))\n",
    "    d.line(face_landmarks['top_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "    d.line(face_landmarks['bottom_lip'], fill=(150, 0, 0, 64), width=8)\n",
    "\n",
    "    # Sparkle the eyes\n",
    "    d.polygon(face_landmarks['left_eye'], fill=(255, 255, 255, 30))\n",
    "    d.polygon(face_landmarks['right_eye'], fill=(255, 255, 255, 30))\n",
    "\n",
    "    # Apply some eyeliner\n",
    "    d.line(face_landmarks['left_eye'] + [face_landmarks['left_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "    d.line(face_landmarks['right_eye'] + [face_landmarks['right_eye'][0]], fill=(0, 0, 0, 110), width=6)\n",
    "\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
